{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitur yang dipakai :\n",
    "- TFIDF Word\n",
    "- WOrd Shape\n",
    "- WH Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T22:14:32.177820Z",
     "start_time": "2020-05-17T22:14:14.341622Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "import re \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T22:14:32.213804Z",
     "start_time": "2020-05-17T22:14:32.181799Z"
    }
   },
   "outputs": [],
   "source": [
    "def wh_tag(doc):\n",
    "    wh_tag_list = {'apa': 1, 'apakah': 2, 'dimana': 3, 'di mana': 3, 'bagaimana':4, 'bagaimanakah':4, 'mengapa':5, 'kenapa':6, 'siapa':7, 'siapakah':7, 'kapan':8, 'kemana':9, 'dari mana':10, 'berapa':11, 'berapakah':11, 'mana':12, 'manakah':12, 'dimanakah':13}\n",
    "    result = []\n",
    "    wh_tags = []\n",
    "    for t in word_tokenize(doc):\n",
    "        if t in wh_tag_list:\n",
    "            wh_tags.append(wh_tag_list[t])\n",
    "    if not wh_tags:#If empty\n",
    "        result.append(0) #none tag\n",
    "    else:\n",
    "        result.append(wh_tags[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T00:15:19.898621Z",
     "start_time": "2020-05-18T00:15:19.466592Z"
    }
   },
   "outputs": [],
   "source": [
    "sen_class = 1\n",
    "\n",
    "target = 'dataset-question-classification-csv.csv'\n",
    "with open(target,'r',encoding='utf-8') as csvFile:\n",
    "    csvReader = csv.reader(csvFile, delimiter=';')\n",
    "    next(csvReader)\n",
    "    \n",
    "    text = []\n",
    "    classes = []\n",
    "    tag_wh_new = []\n",
    "    w_shape_upper = []\n",
    "    w_shape_lower = []\n",
    "    w_shape_digit = []\n",
    "    w_shape_mix = []\n",
    "    w_shape_other = []\n",
    "    \n",
    "    for row in csvReader:\n",
    "        sentence = row[0].lower()\n",
    "        \n",
    "        if sen_class == 1:\n",
    "            sentenceclass =row[1] #row[1]=coarse - row[2]=fine\n",
    "        elif sen_class == 2:\n",
    "            sentenceclass =row[2] #row[1]=coarse - row[2]=fine\n",
    "        classes.append(sentenceclass)\n",
    "        \n",
    "        #Word Shape\n",
    "        shape_upper = 0\n",
    "        shape_lower = 0\n",
    "        shape_digit = 0\n",
    "        shape_mix = 0\n",
    "        shape_other = 0\n",
    "        words = word_tokenize(sentence)\n",
    "        islower = len([word for word in words if word.islower()])\n",
    "        shape_lower += islower\n",
    "        isupper = len([word for word in words if word.isupper()])\n",
    "        shape_upper += isupper\n",
    "        isdigit = len([word for word in words if word.isdigit()])\n",
    "        shape_digit += isdigit\n",
    "        a = [word for word in words if not word.islower() and not word.isupper() and not word.isdigit()]\n",
    "        for x in a:\n",
    "            if x.isalpha() == True:\n",
    "                shape_mix += 1\n",
    "            if x.isalpha() == False:\n",
    "                shape_other+=1\n",
    "        w_shape_upper.append(shape_upper)\n",
    "        w_shape_lower.append(shape_lower)\n",
    "        w_shape_digit.append(shape_digit)\n",
    "        w_shape_mix.append(shape_mix)\n",
    "        w_shape_other.append(shape_other)\n",
    "                \n",
    "        #WH Word\n",
    "        tag_wh_new.append(wh_tag(sentence.lower()))\n",
    "        \n",
    "        text.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T00:15:20.662679Z",
     "start_time": "2020-05-18T00:15:20.296653Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_feature = tfidf_vectorizer.fit_transform(text)\n",
    "documents_text = tfidf_feature.toarray()\n",
    "documents_text = documents_text.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# Insert Word Shape\n",
    "i=0\n",
    "for xxxxx in documents_text:\n",
    "    documents_text[i].insert(0,w_shape_upper[i])\n",
    "    i+=1\n",
    "i=0\n",
    "for xxxxx in documents_text:\n",
    "    documents_text[i].insert(0,w_shape_lower[i])\n",
    "    i+=1\n",
    "i=0\n",
    "for xxxxx in documents_text:\n",
    "    documents_text[i].insert(0,w_shape_digit[i])\n",
    "    i+=1\n",
    "i=0\n",
    "for xxxxx in documents_text:\n",
    "    documents_text[i].insert(0,w_shape_mix[i])\n",
    "    i+=1\n",
    "i=0\n",
    "for xxxxx in documents_text:\n",
    "    documents_text[i].insert(0,w_shape_other[i])\n",
    "    i+=1\n",
    "\n",
    "# Insert WH Tag \n",
    "i=0\n",
    "for xxxxx in documents_text:\n",
    "    documents_text[i].insert(0,tag_wh_new[i][0])\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "a_train, a_test, b_train, b_test = train_test_split(documents_text, classes, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T00:15:29.521334Z",
     "start_time": "2020-05-18T00:15:21.123712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR      0.947     0.857     0.900        21\n",
      "        DESC      0.857     0.750     0.800        48\n",
      "        ENTY      0.829     0.934     0.878       166\n",
      "         HUM      0.978     0.891     0.933       101\n",
      "         LOC      0.869     0.803     0.835        66\n",
      "         NUM      0.979     0.986     0.983       143\n",
      "\n",
      "    accuracy                          0.905       545\n",
      "   macro avg      0.910     0.870     0.888       545\n",
      "weighted avg      0.908     0.905     0.904       545\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM model Coarse Category\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(a_train,b_train)\n",
    "\n",
    "predictions = model.predict(a_test)\n",
    "print(classification_report(b_test,predictions,digits=3))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T00:14:01.135144Z",
     "start_time": "2020-05-18T00:13:49.449297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  abbreviation      0.500     1.000     0.667         5\n",
      "        animal      0.800     0.857     0.828        14\n",
      "          body      1.000     0.667     0.800         6\n",
      "          city      1.000     0.750     0.857         8\n",
      "          code      1.000     0.750     0.857         4\n",
      "         color      1.000     0.900     0.947        10\n",
      "         count      0.633     0.886     0.738        35\n",
      "       country      0.833     0.833     0.833        12\n",
      "      creation      0.500     0.786     0.611        14\n",
      "      currency      1.000     0.800     0.889         5\n",
      "          date      0.929     0.867     0.897        15\n",
      "    definition      0.350     1.000     0.519         7\n",
      "   description      0.429     0.375     0.400         8\n",
      "        dismed      1.000     0.250     0.400        12\n",
      "      distance      0.917     0.917     0.917        12\n",
      "     entyother      0.400     0.533     0.457        15\n",
      "         event      0.375     0.750     0.500         4\n",
      "     expansion      0.800     0.750     0.774        16\n",
      "          food      0.700     0.538     0.609        13\n",
      "         group      0.667     0.800     0.727        10\n",
      "humdescription      1.000     0.857     0.923        14\n",
      "    individual      0.955     0.940     0.947        67\n",
      "    instrument      1.000     1.000     1.000         1\n",
      "      language      1.000     1.000     1.000         2\n",
      "        letter      0.000     0.000     0.000         3\n",
      "      locother      0.636     0.800     0.709        35\n",
      "        manner      0.900     0.750     0.818        12\n",
      "         money      0.632     0.889     0.738        27\n",
      "      mountain      1.000     0.500     0.667         6\n",
      "      numother      1.000     0.200     0.333         5\n",
      "         order      0.000     0.000     0.000         2\n",
      "       percent      0.000     0.000     0.000         8\n",
      "        period      0.818     0.818     0.818        11\n",
      "         plant      1.000     0.250     0.400         4\n",
      "       product      1.000     0.364     0.533        11\n",
      "        reason      0.741     0.952     0.833        21\n",
      "      religion      0.000     0.000     0.000         2\n",
      "          size      1.000     0.600     0.750         5\n",
      "         speed      1.000     0.167     0.286        12\n",
      "         sport      0.889     0.889     0.889         9\n",
      "         state      0.800     0.800     0.800         5\n",
      "     substance      0.600     1.000     0.750         3\n",
      "        symbol      1.000     1.000     1.000         5\n",
      "     technique      1.000     0.600     0.750         5\n",
      "   temperature      0.000     0.000     0.000         1\n",
      "          term      0.800     0.727     0.762        11\n",
      "         title      1.000     0.700     0.824        10\n",
      "       vehicle      0.714     0.714     0.714         7\n",
      "        weight      1.000     0.833     0.909         6\n",
      "          word      0.875     0.700     0.778        10\n",
      "\n",
      "      accuracy                          0.747       545\n",
      "     macro avg      0.744     0.661     0.663       545\n",
      "  weighted avg      0.781     0.747     0.733       545\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fandy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM model Fine Category\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(a_train,b_train)\n",
    "\n",
    "predictions = model.predict(a_test)\n",
    "print(classification_report(b_test,predictions,digits=3))\n",
    "print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
