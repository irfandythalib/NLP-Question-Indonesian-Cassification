{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitur yang dipakai :\n",
    "- TFIDF Word\n",
    "- WH word\n",
    "- Question Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T22:14:06.463795Z",
     "start_time": "2020-05-17T22:14:01.191124Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "import re \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T22:51:46.218446Z",
     "start_time": "2020-05-17T22:51:46.040643Z"
    }
   },
   "outputs": [],
   "source": [
    "def wh_tag(doc):\n",
    "    wh_tag_list = {'apa': 1, 'apakah': 2, 'dimana': 3, 'di mana': 3, 'bagaimana':4, 'bagaimanakah':4, 'mengapa':5, 'kenapa':6, 'siapa':7, 'siapakah':7, 'kapan':8, 'kemana':9, 'dari mana':10, 'berapa':11, 'berapakah':11, 'mana':12, 'manakah':12, 'dimanakah':13}\n",
    "    result = []\n",
    "    wh_tags = []\n",
    "    for t in word_tokenize(doc):\n",
    "        if t in wh_tag_list:\n",
    "            wh_tags.append(wh_tag_list[t])\n",
    "    if not wh_tags:#If empty\n",
    "        result.append(0) #none tag\n",
    "    else:\n",
    "        result.append(wh_tags[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T00:15:28.193235Z",
     "start_time": "2020-05-18T00:15:27.986222Z"
    }
   },
   "outputs": [],
   "source": [
    "sen_class = 1\n",
    "\n",
    "target = 'dataset-question-classification-csv.csv'\n",
    "with open(target,'r',encoding='utf-8') as csvFile:\n",
    "    csvReader = csv.reader(csvFile, delimiter=';')\n",
    "    next(csvReader)\n",
    "    \n",
    "    text = []\n",
    "    classes = []\n",
    "    tag_wh_new = []\n",
    "    question_length = []\n",
    "    \n",
    "    for row in csvReader:\n",
    "        \n",
    "        sentence = row[0].lower()\n",
    "        \n",
    "        if sen_class == 1:\n",
    "            sentenceclass =row[1] #row[1]=coarse - row[2]=fine\n",
    "        elif sen_class == 2:\n",
    "            sentenceclass =row[2] #row[1]=coarse - row[2]=fine\n",
    "        classes.append(sentenceclass)\n",
    "        \n",
    "        #Question length\n",
    "        q_length = len(re.findall(r'\\w+', sentence)) \n",
    "        question_length.append(q_length)\n",
    "        \n",
    "        #WH Word\n",
    "        tag_wh_new.append(wh_tag(sentence.lower()))\n",
    "        \n",
    "        text.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T00:15:28.919287Z",
     "start_time": "2020-05-18T00:15:28.566265Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_feature = tfidf_vectorizer.fit_transform(text)\n",
    "documents_text = tfidf_feature.toarray()\n",
    "documents_text = documents_text.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# Insert Question Length\n",
    "i=0\n",
    "for xxxxx in documents_text:\n",
    "    documents_text[i].insert(0,question_length[i])\n",
    "    i+=1\n",
    "\n",
    "# Insert WH Tag \n",
    "i=0\n",
    "for xxxxx in documents_text:\n",
    "    documents_text[i].insert(0,tag_wh_new[i][0])\n",
    "    i+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "a_train, a_test, b_train, b_test = train_test_split(documents_text, classes, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T00:15:38.421996Z",
     "start_time": "2020-05-18T00:15:29.252315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR      0.947     0.857     0.900        21\n",
      "        DESC      0.857     0.750     0.800        48\n",
      "        ENTY      0.829     0.934     0.878       166\n",
      "         HUM      0.978     0.891     0.933       101\n",
      "         LOC      0.883     0.803     0.841        66\n",
      "         NUM      0.972     0.986     0.979       143\n",
      "\n",
      "    accuracy                          0.905       545\n",
      "   macro avg      0.911     0.870     0.889       545\n",
      "weighted avg      0.908     0.905     0.904       545\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM model Coarse Category\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(a_train,b_train)\n",
    "\n",
    "predictions = model.predict(a_test)\n",
    "print(classification_report(b_test,predictions,digits=3))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T00:14:07.701630Z",
     "start_time": "2020-05-18T00:13:56.592808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "  abbreviation      0.556     1.000     0.714         5\n",
      "        animal      0.833     0.714     0.769        14\n",
      "          body      1.000     0.500     0.667         6\n",
      "          city      1.000     0.750     0.857         8\n",
      "          code      1.000     0.750     0.857         4\n",
      "         color      1.000     0.900     0.947        10\n",
      "         count      0.585     0.886     0.705        35\n",
      "       country      0.846     0.917     0.880        12\n",
      "      creation      0.462     0.857     0.600        14\n",
      "      currency      1.000     0.800     0.889         5\n",
      "          date      0.933     0.933     0.933        15\n",
      "    definition      0.350     1.000     0.519         7\n",
      "   description      0.500     0.375     0.429         8\n",
      "        dismed      1.000     0.250     0.400        12\n",
      "      distance      0.917     0.917     0.917        12\n",
      "     entyother      0.381     0.533     0.444        15\n",
      "         event      0.214     0.750     0.333         4\n",
      "     expansion      0.800     0.750     0.774        16\n",
      "          food      0.778     0.538     0.636        13\n",
      "         group      0.636     0.700     0.667        10\n",
      "humdescription      1.000     0.857     0.923        14\n",
      "    individual      0.969     0.925     0.947        67\n",
      "    instrument      1.000     1.000     1.000         1\n",
      "      language      1.000     1.000     1.000         2\n",
      "        letter      0.000     0.000     0.000         3\n",
      "      locother      0.707     0.829     0.763        35\n",
      "        manner      0.900     0.750     0.818        12\n",
      "         money      0.649     0.889     0.750        27\n",
      "      mountain      1.000     0.500     0.667         6\n",
      "      numother      1.000     0.200     0.333         5\n",
      "         order      0.000     0.000     0.000         2\n",
      "       percent      0.000     0.000     0.000         8\n",
      "        period      0.818     0.818     0.818        11\n",
      "         plant      1.000     0.250     0.400         4\n",
      "       product      1.000     0.273     0.429        11\n",
      "        reason      0.769     0.952     0.851        21\n",
      "      religion      0.000     0.000     0.000         2\n",
      "          size      1.000     0.600     0.750         5\n",
      "         speed      1.000     0.167     0.286        12\n",
      "         sport      0.900     1.000     0.947         9\n",
      "         state      0.800     0.800     0.800         5\n",
      "     substance      0.600     1.000     0.750         3\n",
      "        symbol      1.000     1.000     1.000         5\n",
      "     technique      1.000     0.400     0.571         5\n",
      "   temperature      0.000     0.000     0.000         1\n",
      "          term      0.900     0.818     0.857        11\n",
      "         title      1.000     0.700     0.824        10\n",
      "       vehicle      0.714     0.714     0.714         7\n",
      "        weight      1.000     0.833     0.909         6\n",
      "          word      1.000     0.700     0.824        10\n",
      "\n",
      "      accuracy                          0.745       545\n",
      "     macro avg      0.750     0.656     0.657       545\n",
      "  weighted avg      0.792     0.745     0.733       545\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fandy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM model Coarse Category\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(a_train,b_train)\n",
    "\n",
    "predictions = model.predict(a_test)\n",
    "print(classification_report(b_test,predictions,digits=3))\n",
    "print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
